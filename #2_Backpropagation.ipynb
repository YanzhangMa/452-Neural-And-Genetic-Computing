{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "A2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf798513"
      },
      "source": [
        "# CISC 452 Assignment 2 - Backpropagation (100 points)  \n",
        "\n",
        "Please put your name and student id\n",
        "\n",
        "    Yanzhang Ma, #20090412\n",
        "\n",
        "- The notebook file has clearly marked blocks where you are expected to write code. Do not write or modify any code outside of these blocks.\n",
        "- Do not add or delete cells from the notebook.\n",
        "- Run all cells, and do not clear out the outputs, before submitting. You will only get credit for code that has been run.\n",
        "- Make sure to run all the cells from beginning before the submission"
      ],
      "id": "cf798513"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRLNrFDU3dKp"
      },
      "source": [
        "## [Part 1 (60 points)](#Part-1)  \n",
        "\n",
        "### Build Model1 (50 points)  \n",
        "Use Pytorch to implement a three-layer Neural Network (input layer - hidden layer - output layer) and update the weights with backpropagation  \n",
        "- 1. Implement forward and calculate the output (10 points)  \n",
        "- 2. Calculate errors and loss (10 points)  \n",
        "- 3. Update the weights with backpropagation (20 points)  \n",
        "- 4. Predict function (5 points)  \n",
        "- 5. Activation function (Sigmoid function) (5 points)  \n",
        "\n",
        "### Evaluate Model1 (10 points)  \n",
        "Use the predict function to predict the labels with the test dataset (5 points)  \n",
        "Evaluate the prediction results (5 points)   \n",
        "- Evaluation matrices include confusion matrix, accuracy, recall score, precision and F1 score\n",
        "\n",
        "## [Part 2 (40 points)](#Part-2)  \n",
        "\n",
        "Use another machine learning framework (**scikit-learn, Tensorflow and Pytorch**) to build MLP\n",
        "e.g. \n",
        "  1. https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "  2. https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "  3. https://pytorch.org/tutorials/beginner/examples_nn/polynomial_nn.html#sphx-glr-beginner-examples-nn-polynomial-nn-py\n",
        "  \n",
        "### Build Model2-1 (15 points)  \n",
        "Implement model 2-1 with the same hidden nodes and optimization function as the model in Part 1  \n",
        "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
        "\n",
        "### Evaluate Model2-1 (5 points)\n",
        "Evaluate the prediction results (5 points)   \n",
        "- Evaluation matrices include confusion matrix, accuracy, recall score, precision and F1 score\n",
        "\n",
        "### Build Model2-2 (15 points)  \n",
        "Add one more hidden layer (2 hidden layers in total) to the model  \n",
        "Describe Model 2-2 (number of hidden nodes)  \n",
        "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
        "\n",
        "### Evaluate Model2-2 (5 points)\n",
        "Evaluate the prediction results (5 points)   \n",
        "- Evaluation matrices include confusion matrix, accuracy, recall score, precision and F1 score"
      ],
      "id": "VRLNrFDU3dKp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7e6a263"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets import MNIST"
      ],
      "id": "b7e6a263",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKE_KANU7_sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a84953d-38e2-485e-e2fa-12cfef48cec0"
      },
      "source": [
        "# make sure you are using GPU, or you can go to Edit - Notebook settings to select under the Hardware accelerator\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "eKE_KANU7_sq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a5cbc46"
      },
      "source": [
        "# build the dataset (train, validation and test)\n",
        "\n",
        "def load_MNIST(n_val=10000, n_sample=1000, sample=False):\n",
        "    n_val = n_val\n",
        "    n_sample = n_sample\n",
        "    train = MNIST(root = '.', train = True, download = True)\n",
        "    test = MNIST(root = '.', train = False, download = True)\n",
        "    \n",
        "    # data preprocessing\n",
        "    x_train, x_test = train.data/255, test.data/255\n",
        "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "    y_train = torch.nn.functional.one_hot(train.targets)\n",
        "    y_test = torch.nn.functional.one_hot(test.targets)\n",
        "\n",
        "    data_dict = {}\n",
        "    if sample:\n",
        "        data_dict['x_train'] = x_train[:-n_val][:n_sample]\n",
        "        data_dict['y_train'] = y_train[:-n_val][:n_sample]\n",
        "        data_dict['x_val'] = x_train[-n_val:][:n_sample//10]\n",
        "        data_dict['y_val'] = y_train[-n_val:][:n_sample//10]\n",
        "        data_dict['x_test'] = x_test[:n_sample//10]\n",
        "        data_dict['y_test'] = y_test[:n_sample//10]\n",
        "    else:\n",
        "        data_dict['x_train'] = x_train[:-n_val]\n",
        "        data_dict['y_train'] = y_train[:-n_val]\n",
        "        data_dict['x_val'] = x_train[-n_val:]\n",
        "        data_dict['y_val'] = y_train[-n_val:]\n",
        "        data_dict['x_test'] = x_test\n",
        "        data_dict['y_test'] = y_test\n",
        "    return data_dict"
      ],
      "id": "9a5cbc46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBq2HsIn5by4",
        "outputId": "254b7894-64f9-4e9b-ca99-57cb902ac8fd"
      },
      "source": [
        "print(data_dict)"
      ],
      "id": "jBq2HsIn5by4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x_train': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'y_train': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0]]), 'x_val': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'y_val': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 1, 0]]), 'x_test': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'y_test': tensor([[0, 0, 0,  ..., 1, 0, 0],\n",
            "        [0, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5G-vmpD21Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601,
          "referenced_widgets": [
            "912c8d5e7aaf4c77831f94498b9cde3a",
            "e12f4648253a48569f84904bc2d166bc",
            "f9eed27195014199bc9fe978f03acac8",
            "c21241f1db604b308e775f6a6828cd4f"
          ]
        },
        "outputId": "03e4b92b-cf7b-4c27-85a6-742e0aefca20"
      },
      "source": [
        "# you can start with a small sample dataset by setting sample=True\n",
        "data_dict = load_MNIST(sample=False)\n",
        "print('Train data shape:', data_dict['x_train'].shape)\n",
        "print('Train labels shape:', data_dict['y_train'].shape)\n",
        "print('Validation data shape:', data_dict['x_val'].shape)\n",
        "print('Validation labels shape:', data_dict['y_val'].shape)\n",
        "print('Test data shape:', data_dict['x_test'].shape)\n",
        "print('Test labels shape:', data_dict['y_test'].shape)"
      ],
      "id": "Q5G-vmpD21Bj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "912c8d5e7aaf4c77831f94498b9cde3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e12f4648253a48569f84904bc2d166bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9eed27195014199bc9fe978f03acac8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c21241f1db604b308e775f6a6828cd4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: torch.Size([50000, 784])\n",
            "Train labels shape: torch.Size([50000, 10])\n",
            "Validation data shape: torch.Size([10000, 784])\n",
            "Validation labels shape: torch.Size([10000, 10])\n",
            "Test data shape: torch.Size([10000, 784])\n",
            "Test labels shape: torch.Size([10000, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32087af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3436bb5b-e1d2-474e-9998-b0ab864b972b"
      },
      "source": [
        "# check the data distribution if you use a sample dataset to avoid imbanlance dataset\n",
        "for i in range(10):\n",
        "    print(torch.sum(torch.argmax(data_dict['y_test'], dim=1)==i))"
      ],
      "id": "32087af6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(980)\n",
            "tensor(1135)\n",
            "tensor(1032)\n",
            "tensor(1010)\n",
            "tensor(982)\n",
            "tensor(892)\n",
            "tensor(958)\n",
            "tensor(1028)\n",
            "tensor(974)\n",
            "tensor(1009)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aa9f016",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4bff5455-9438-4afa-948e-b470900d377c"
      },
      "source": [
        "# plot an example\n",
        "plt.imshow(data_dict['x_train'][0].reshape(28, 28))\n",
        "plt.title(data_dict['y_train'][0].argmax().item())\n",
        "plt.show()"
      ],
      "id": "1aa9f016",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6291c647"
      },
      "source": [
        "# TODO: use the predict function to predict the lables with the test dataset\n",
        "# TODO: evaluate the prediction results (accuracy, recall score, precision and F1 score)\n",
        "####################################################################################################\n",
        "# enter code here to calculate the hidden layer output and output layer output\n",
        "# Write a function to analyze the result\n",
        "def evaluator(test_y, pred_y):\n",
        "  tp=0\n",
        "  tn=0\n",
        "  fp=0\n",
        "  fn=0\n",
        "  for i,j in zip(y_test, y_pred):\n",
        "      if i==j==1:\n",
        "          tp+=1\n",
        "      elif i==j==0:\n",
        "          tn+=1\n",
        "      elif (i==0) and (j==1):\n",
        "          fp+=1\n",
        "      else:\n",
        "          fn+=1\n",
        "            \n",
        "  confusion_matrix = [[tp,tn],[fp,fn]]\n",
        "  print(\"Confusion Matrix:\\n\",confusion_matrix)\n",
        "  accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "  print(\"accuracy:\\n\",accuracy)\n",
        "  precision=tp/(tp+fp)\n",
        "  print(\"precision:\\n\",precision)\n",
        "  recall=tp/(tp+fn)\n",
        "  print(\"recall:\\n\",recall)\n",
        "  F1_score=(2*tp)/(2*tp+fn+fp)\n",
        "  print(\"F1_score:\\n\",F1_score)\n",
        "\n",
        "####################################################################################################"
      ],
      "id": "6291c647",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y6EcHUepq8c",
        "outputId": "60fd70dc-31b1-402c-d2f4-193fc2b9dbc0"
      },
      "source": [
        "print(torch.sigmoid(torch.tensor([1,2,3,0])))"
      ],
      "id": "_Y6EcHUepq8c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7311, 0.8808, 0.9526, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4a6b06"
      },
      "source": [
        "## Part 1"
      ],
      "id": "4e4a6b06"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0d3fc2d"
      },
      "source": [
        "class NN(object):\n",
        "    def __init__(self, hidden_size, device, dtype=torch.float32):\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "        self.dtype = dtype\n",
        "        self.history = {}\n",
        "        self.history['train_acc'], self.history['val_acc'], self.history['loss'] = [], [], []\n",
        "        \n",
        "    def sigmoid(self, x):\n",
        "        ####################################################################################################\n",
        "        # 5. enter code here to implement the activation function\n",
        "        return torch.sigmoid(x)\n",
        "        ####################################################################################################\n",
        "\n",
        "    def train(self, x, y, x_val, y_val, learning_rate=0.001, n_iters=100, batch_size=200, verbose=0):\n",
        "        n_train = x.shape[0]\n",
        "        n_val = x_val.shape[0]\n",
        "        input_size = x.shape[1]\n",
        "        num_classes = y.shape[1]\n",
        "        \n",
        "        self.params = {}\n",
        "        ####################################################################################################\n",
        "        # You can change the initialzation here if you want\n",
        "        self.W1 = torch.randn(input_size, self.hidden_size, dtype=self.dtype, device=self.device) * 0.01\n",
        "        self.b1 = torch.zeros(self.hidden_size, dtype=self.dtype, device=self.device)\n",
        "        self.W2 = torch.randn(self.hidden_size, num_classes, dtype=self.dtype, device=self.device) * 0.01\n",
        "        self.b2 = torch.zeros(num_classes, dtype=self.dtype, device=self.device)\n",
        "        ####################################################################################################\n",
        "\n",
        "\n",
        "        # TODO: train the weights with the input data and labels\n",
        "        for i in range(n_iters):\n",
        "            loss = 0\n",
        "            data = getBatch(x, y, batch_size)\n",
        "            for x_batch, y_batch in data:\n",
        "                x_batch = x_batch[0]\n",
        "                y_batch = y_batch[0]\n",
        "                ####################################################################################################\n",
        "                # 1. enter code here to calculate the hidden layer output and output layer output\n",
        "                hidden_input = torch.matmul(x_batch,self.W1)\n",
        "                hidden_output = self.sigmoid(hidden_input+self.b1)\n",
        "                final_input = torch.matmul(hidden_output,self.W2)\n",
        "                final_output = self.sigmoid(final_input+self.b2)\n",
        "\n",
        "                ####################################################################################################\n",
        "\n",
        "                ####################################################################################################\n",
        "                # 2. enter code here to calculate the hidden layer error, output layer error and loss\n",
        "                output_error = y_batch - final_output\n",
        "                hidden_error = torch.matmul(output_error,self.W2.T)\n",
        "                # loss\n",
        "                loss = output_error**2\n",
        "                \n",
        "                ####################################################################################################\n",
        "\n",
        "               \n",
        "\n",
        "                # backward\n",
        "                ####################################################################################################\n",
        "                # 3. enter code here to update the weights with the errors\n",
        "                self.W1+=learning_rate*torch.matmul(torch.transpose(hidden_output,0,1),(output_error*final_output*(1.0-final_output)))\n",
        "                self.W2+=learning_rate*torch.matmul(torch.transpose(x_batch,0,1),(hidden_error*hidden_output*(1.0-hidden_output)))\n",
        "                \n",
        "                ####################################################################################################\n",
        "            \n",
        "            # calculate the accuracy\n",
        "            y_pred = self.predict(x)\n",
        "            train_acc = torch.sum(torch.argmax(y, dim=1) == torch.argmax(y_pred, dim=1)) / n_train\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['loss'].append(loss)\n",
        "            \n",
        "            y_pred = self.predict(x_val)\n",
        "            val_acc = torch.sum(torch.argmax(y_val, dim=1) == torch.argmax(y_pred, dim=1)) / n_val\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            if verbose:\n",
        "                print('epoch %d, loss %.4f, train acc %.3f, validation acc %.3f'\n",
        "                  % (i + 1, loss, train_acc, val_acc))\n",
        "                \n",
        "    def predict(self, x):\n",
        "        ####################################################################################################\n",
        "        # 4. enter code here to complete the predict function\n",
        "        # TODO: use the trained weights to predict labels and return the predicted labels\n",
        "        hidden_output=self.sigmoid(torch.matmul(x,self.W1)+self.b1)\n",
        "        output=self.sigmoid(torch.matmul(hidden_output,self.W2)+self.b2)\n",
        "        y_pred=output\n",
        "        ####################################################################################################\n",
        "        return y_pred\n",
        "\n",
        "def getBatch(x, y, batch_size):\n",
        "    n_epoch = x.shape[0] // batch_size\n",
        "    for i in range(n_epoch):\n",
        "        x_batch = x[i * batch_size : (i+1) * batch_size]\n",
        "        y_batch = y[i * batch_size : (i+1) * batch_size]\n",
        "        yield x_batch, y_batch\n",
        "    x_batch = x[(i+1) * batch_size:]\n",
        "    y_batch = y[(i+1) * batch_size:]    \n",
        "    yield x_batch, y_batch"
      ],
      "id": "a0d3fc2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74e9819c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "f59f2ac5-3e26-419d-9645-a36d3f76e0e1"
      },
      "source": [
        "####################################################################################################\n",
        "# enter code here to tune the parameters\n",
        "# TODO: set your desired hidden size, learning rate, number of iterations and batch size\n",
        "hidden_size = 100\n",
        "\n",
        "model = NN(hidden_size, device)\n",
        "model.train(data_dict['x_train'].to(device),\n",
        "            data_dict['y_train'].to(device),\n",
        "            data_dict['x_val'].to(device),\n",
        "            data_dict['y_val'].to(device), \n",
        "            learning_rate=0.01,\n",
        "            n_iters=10,\n",
        "            batch_size=1,\n",
        "            verbose=1)\n",
        "####################################################################################################"
      ],
      "id": "74e9819c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-ab7456ff9312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             verbose=1)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m####################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-cf6e9d9dffae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, x_val, y_val, learning_rate, n_iters, batch_size, verbose)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m####################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# 3. enter code here to update the weights with the errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_error\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_error\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhidden_output\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhidden_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bebd0600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "50752e68-d05e-4597-ec84-e2695d4037f9"
      },
      "source": [
        "plt.plot(model.history['train_acc'], label='train_acc')\n",
        "plt.plot(model.history['val_acc'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "bebd0600",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQciuqY96_6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "b4a9a5b2-2dab-4d72-f7ff-e62aabf169e4"
      },
      "source": [
        "y_pred = model.predict(data_dict['x_test'].to(device))\n",
        "evaluator(data_dict['y_test'].argmax(dim=1), torch.argmax(y_pred, dim=1).cpu())"
      ],
      "id": "UQciuqY96_6Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-379a0391e72e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6b0adbd8fcc4>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m####################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NN' object has no attribute 'f'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhkkGjWwxlLJ"
      },
      "source": [
        ""
      ],
      "id": "bhkkGjWwxlLJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_rb7uJ4XDL"
      },
      "source": [
        "## Part 2"
      ],
      "id": "QG_rb7uJ4XDL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27799f22"
      },
      "source": [
        "### Model2-1"
      ],
      "id": "27799f22"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8abf8b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f6c70e-ecd7-4e0f-ce0d-64dd273b84d4"
      },
      "source": [
        "####################################################################################################\n",
        "# enter code here to implement evaluate Model2-1\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "def model():\n",
        "  input_dim=Input(784)\n",
        "  layer1 = Dense(100, activation='sigmoid')(input_dim)\n",
        "  output = Dense(10, activation= 'sigmoid')(layer1)\n",
        "  model = tf.keras.Model(inputs=input_dim, outputs=output)\n",
        "  return model\n",
        "\n",
        "model1=model()\n",
        "model1.compile(optimizer=tf.keras.optimizers.Adam(),loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "print(model1.summary())\n",
        "####################################################################################################"
      ],
      "id": "8abf8b4f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PetG79-TyMlI"
      },
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy\n",
        "x_train=data_dict['x_train']\n",
        "y_train=data_dict['y_train']\n",
        "x_test=data_dict['x_test']\n",
        "y_test=data_dict['y_test']\n",
        "x_val=data_dict['x_val']\n",
        "y_val=data_dict['y_val']\n",
        "\n",
        "x_train=tf.convert_to_tensor(x_train.numpy())\n",
        "y_train=tf.convert_to_tensor(y_train.numpy())\n",
        "x_test=tf.convert_to_tensor(x_test.numpy())\n",
        "y_test=tf.convert_to_tensor(y_test.numpy())\n",
        "x_val=tf.convert_to_tensor(x_val.numpy())\n",
        "y_val=tf.convert_to_tensor(y_val.numpy())\n"
      ],
      "id": "PetG79-TyMlI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2XgJ5ODC-ts",
        "outputId": "14bd96f9-4bdb-46b7-d772-56be915d4e8f"
      },
      "source": [
        "epochs=16\n",
        "batch_size=64\n",
        "history=model1.fit(x=x_train,y=y_train,batch_size=batch_size,validation_data=(x_val,y_val),epochs=epochs)"
      ],
      "id": "r2XgJ5ODC-ts",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.0390 - accuracy: 0.8095 - val_loss: 0.0180 - val_accuracy: 0.9134\n",
            "Epoch 2/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0165 - accuracy: 0.9137 - val_loss: 0.0127 - val_accuracy: 0.9315\n",
            "Epoch 3/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0127 - accuracy: 0.9295 - val_loss: 0.0106 - val_accuracy: 0.9415\n",
            "Epoch 4/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9394 - val_loss: 0.0092 - val_accuracy: 0.9488\n",
            "Epoch 5/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0093 - accuracy: 0.9470 - val_loss: 0.0083 - val_accuracy: 0.9544\n",
            "Epoch 6/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0083 - accuracy: 0.9537 - val_loss: 0.0076 - val_accuracy: 0.9575\n",
            "Epoch 7/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9584 - val_loss: 0.0071 - val_accuracy: 0.9610\n",
            "Epoch 8/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0068 - accuracy: 0.9627 - val_loss: 0.0067 - val_accuracy: 0.9629\n",
            "Epoch 9/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0062 - accuracy: 0.9655 - val_loss: 0.0064 - val_accuracy: 0.9646\n",
            "Epoch 10/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9688 - val_loss: 0.0060 - val_accuracy: 0.9670\n",
            "Epoch 11/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9719 - val_loss: 0.0058 - val_accuracy: 0.9671\n",
            "Epoch 12/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0049 - accuracy: 0.9746 - val_loss: 0.0055 - val_accuracy: 0.9693\n",
            "Epoch 13/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0045 - accuracy: 0.9769 - val_loss: 0.0054 - val_accuracy: 0.9688\n",
            "Epoch 14/16\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.0042 - accuracy: 0.9789 - val_loss: 0.0052 - val_accuracy: 0.9712\n",
            "Epoch 15/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0039 - accuracy: 0.9804 - val_loss: 0.0051 - val_accuracy: 0.9709\n",
            "Epoch 16/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9819 - val_loss: 0.0051 - val_accuracy: 0.9718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crf-Yj3MRNyp",
        "outputId": "00a47805-4ee3-452b-8a71-470b3db0adab"
      },
      "source": [
        "import numpy\n",
        "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_predict_raw=model1.predict(x_test)\n",
        "def evaluator(y_test,y_predict_raw):\n",
        "  max_predict=numpy.amax(y_predict_raw,axis=1)\n",
        "  array_predict=numpy.array([max_predict])\n",
        "  y_predict=(y_predict_raw==numpy.transpose(array_predict))\n",
        "  #print(np.vectorize(y_predict))\n",
        "  #print(y_predict)\n",
        "  print(\"Confusion matrix:\\n\",confusion_matrix(y_test.numpy().argmax(axis=1),y_predict.argmax(axis=1)))\n",
        "  print(\"\\nReport:\\n\",classification_report(y_test.numpy().argmax(axis=1),y_predict.argmax(axis=1)))\n",
        "  return None\n",
        "\n",
        "evaluator(y_test,y_predict_raw)"
      ],
      "id": "crf-Yj3MRNyp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[ 963    0    1    2    0    3    7    2    1    1]\n",
            " [   0 1121    4    1    0    1    4    1    3    0]\n",
            " [   6    1  994    3    3    2    7    6   10    0]\n",
            " [   0    0    6  983    0    6    1    4    6    4]\n",
            " [   1    0    2    0  949    0    8    1    2   19]\n",
            " [   2    0    1   10    1  857    8    1    8    4]\n",
            " [   4    3    1    1    3    4  937    0    5    0]\n",
            " [   0    5   14    8    0    1    0  985    3   12]\n",
            " [   6    0    1    4    5    3    2    2  949    2]\n",
            " [   6    6    1    8   11    3    0    5    5  964]]\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.96      0.97      1032\n",
            "           3       0.96      0.97      0.97      1010\n",
            "           4       0.98      0.97      0.97       982\n",
            "           5       0.97      0.96      0.97       892\n",
            "           6       0.96      0.98      0.97       958\n",
            "           7       0.98      0.96      0.97      1028\n",
            "           8       0.96      0.97      0.97       974\n",
            "           9       0.96      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8557afca"
      },
      "source": [
        "### Model2-2"
      ],
      "id": "8557afca"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85d207b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04595333-bfc7-48b8-9591-a74232ee4332"
      },
      "source": [
        "####################################################################################################\n",
        "# enter code here to implement evaluate Model2-2\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "def model():\n",
        "  input_dim=Input(784)\n",
        "  layer1 = Dense(100,activation='sigmoid')(input_dim)\n",
        "  layer2 = Dense(20,activation='relu')(layer1)\n",
        "  output = Dense(10,activation= 'sigmoid')(layer2)\n",
        "  model = tf.keras.Model(inputs=input_dim, outputs=output)\n",
        "  return model\n",
        "\n",
        "model2=model()\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(),loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "print(model2.summary())\n",
        "\n",
        "\n",
        "####################################################################################################"
      ],
      "id": "85d207b8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 20)                2020      \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 80,730\n",
            "Trainable params: 80,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYhq2YbOD80O"
      },
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy\n",
        "x_train=data_dict['x_train']\n",
        "y_train=data_dict['y_train']\n",
        "x_test=data_dict['x_test']\n",
        "y_test=data_dict['y_test']\n",
        "x_val=data_dict['x_val']\n",
        "y_val=data_dict['y_val']\n",
        "\n",
        "x_train=tf.convert_to_tensor(x_train.numpy())\n",
        "y_train=tf.convert_to_tensor(y_train.numpy())\n",
        "x_test=tf.convert_to_tensor(x_test.numpy())\n",
        "y_test=tf.convert_to_tensor(y_test.numpy())\n",
        "x_val=tf.convert_to_tensor(x_val.numpy())\n",
        "y_val=tf.convert_to_tensor(y_val.numpy())"
      ],
      "id": "AYhq2YbOD80O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qhn-EJeD-3V",
        "outputId": "fa14c227-c794-4dd1-ea1c-784aa41b7729"
      },
      "source": [
        "epochs=16\n",
        "batch_size=64\n",
        "history=model2.fit(x=x_train,y=y_train,batch_size=batch_size,validation_data=(x_val,y_val),epochs=epochs)"
      ],
      "id": "0Qhn-EJeD-3V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "782/782 [==============================] - 4s 4ms/step - loss: 0.0495 - accuracy: 0.7332 - val_loss: 0.0184 - val_accuracy: 0.9071\n",
            "Epoch 2/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0161 - accuracy: 0.9104 - val_loss: 0.0122 - val_accuracy: 0.9280\n",
            "Epoch 3/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0115 - accuracy: 0.9346 - val_loss: 0.0096 - val_accuracy: 0.9441\n",
            "Epoch 4/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9471 - val_loss: 0.0080 - val_accuracy: 0.9529\n",
            "Epoch 5/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9555 - val_loss: 0.0073 - val_accuracy: 0.9563\n",
            "Epoch 6/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9601 - val_loss: 0.0068 - val_accuracy: 0.9602\n",
            "Epoch 7/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0061 - accuracy: 0.9651 - val_loss: 0.0063 - val_accuracy: 0.9635\n",
            "Epoch 8/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9689 - val_loss: 0.0060 - val_accuracy: 0.9664\n",
            "Epoch 9/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0050 - accuracy: 0.9724 - val_loss: 0.0059 - val_accuracy: 0.9655\n",
            "Epoch 10/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0045 - accuracy: 0.9753 - val_loss: 0.0057 - val_accuracy: 0.9676\n",
            "Epoch 11/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0041 - accuracy: 0.9783 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
            "Epoch 12/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0037 - accuracy: 0.9802 - val_loss: 0.0052 - val_accuracy: 0.9699\n",
            "Epoch 13/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9822 - val_loss: 0.0051 - val_accuracy: 0.9704\n",
            "Epoch 14/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0032 - accuracy: 0.9834 - val_loss: 0.0054 - val_accuracy: 0.9707\n",
            "Epoch 15/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0029 - accuracy: 0.9848 - val_loss: 0.0049 - val_accuracy: 0.9723\n",
            "Epoch 16/16\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0027 - accuracy: 0.9865 - val_loss: 0.0048 - val_accuracy: 0.9717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTgzylY9E1yR",
        "outputId": "aaba45a0-d65e-4fd3-c35a-9c87d43e2d50"
      },
      "source": [
        "import numpy\n",
        "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_predict_raw=model2.predict(x_test)\n",
        "def evaluator(y_test,y_predict_raw):\n",
        "  max_predict=numpy.amax(y_predict_raw,axis=1)\n",
        "  array_predict=numpy.array([max_predict])\n",
        "  y_predict=(y_predict_raw==numpy.transpose(array_predict))\n",
        "  #print(np.vectorize(y_predict))\n",
        "  #print(y_predict)\n",
        "  print(\"Confusion matrix:\\n\",confusion_matrix(y_test.numpy().argmax(axis=1),y_predict.argmax(axis=1)))\n",
        "  print(\"\\nReport:\\n\",classification_report(y_test.numpy().argmax(axis=1),y_predict.argmax(axis=1)))\n",
        "  return None\n",
        "\n",
        "evaluator(y_test,y_predict_raw)"
      ],
      "id": "FTgzylY9E1yR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[ 966    0    1    4    0    2    4    1    1    1]\n",
            " [   0 1121    2    3    0    1    4    1    3    0]\n",
            " [   5    2  993    9    2    1    5    6    9    0]\n",
            " [   1    1    5  980    1    6    0    5   11    0]\n",
            " [   1    0    4    1  956    1    7    3    1    8]\n",
            " [   5    0    0    9    1  861    9    2    3    2]\n",
            " [   7    3    1    1    1    4  940    0    1    0]\n",
            " [   0    5   11    6    1    1    0  995    3    6]\n",
            " [   4    0    5    6    3    3    6    7  939    1]\n",
            " [   6    3    3    9   10    2    0   12    5  959]]\n",
            "\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.96      0.97      1032\n",
            "           3       0.95      0.97      0.96      1010\n",
            "           4       0.98      0.97      0.98       982\n",
            "           5       0.98      0.97      0.97       892\n",
            "           6       0.96      0.98      0.97       958\n",
            "           7       0.96      0.97      0.97      1028\n",
            "           8       0.96      0.96      0.96       974\n",
            "           9       0.98      0.95      0.97      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}